{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "colab_type": "code",
    "id": "GOF52wJl6FbB",
    "outputId": "9323455d-4229-4d71-ac60-0038263eac1c"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "Mo5LdP5n67az",
    "outputId": "ca4144ba-f0eb-41a4-a72e-bbc433ac30ee"
   },
   "outputs": [],
   "source": [
    "!rm -r DialogueBot\n",
    "!git clone https://github.com/ressay/DialogueBot.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "figYChXmedwB",
    "outputId": "747e50d1-fbf8-44c5-8980-ec95b56ab46c"
   },
   "outputs": [],
   "source": [
    "!pip install rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkgVGk_E88LU"
   },
   "outputs": [],
   "source": [
    "!pip install -r DialogueBot/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWcbV_bTW62g"
   },
   "outputs": [],
   "source": [
    "!mkdir my_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ETRIk7eJ-_jh",
    "outputId": "7209a3a0-0b66-4c7f-b522-f997d09cb57c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \".\")\n",
    "from DialogueManager.FileBrowserDM.agent import AgentFB\n",
    "from DialogueManager.FileBrowserDM.user_simulator import UserSimulatorFB\n",
    "from DialogueManager.FileBrowserDM.file_tree_sim import FileTreeSimulator\n",
    "from DialogueManager.FileBrowserDM.nlg import Nlg_system\n",
    "from DialogueManager.error_model_controller import ErrorModelController\n",
    "import Ontologies.onto_fbrowser as fbrowser\n",
    "import argparse, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hk9D15dGTmDp"
   },
   "outputs": [],
   "source": [
    "CONSTANTS_FILE_PATH = 'DialogueManager/FileBrowserDM/constants.json'\n",
    "constants_file = CONSTANTS_FILE_PATH\n",
    "\n",
    "consts = {\n",
    "  \"run\": {\n",
    "    \"usersim\": True,\n",
    "    \"warmup_mem\": 1000,\n",
    "    \"num_ep_run\": 40000,\n",
    "    \"train_freq\": 100,\n",
    "    \"max_round_num\": 40,\n",
    "    \"success_rate_threshold\": 0.3\n",
    "  },\n",
    "  \"agent\": {\n",
    "    \"save_weights_file_path\": \"my_weights/m.h5\",\n",
    "    \"load_weights_file_path\": 0,\n",
    "    \"vanilla\": True,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 128,\n",
    "    \"dqn_hidden_size\": 80,\n",
    "    \"epsilon_init\": 0.5,\n",
    "    \"gamma\": 0.7,\n",
    "    \"max_mem_size\": 50000,\n",
    "    \"agent_actions\": [\"Create_file\",\"Delete_file\",\"Change_directory\",\n",
    "      \"inform\",\"ask\",\"request\"]\n",
    "  },\n",
    "  \"emc\": {\n",
    "    \"slot_error_mode\": 0,\n",
    "    \"slot_error_prob\": 0.05,\n",
    "    \"intent_error_prob\": 0.0\n",
    "  }\n",
    "}\n",
    "with open(constants_file, 'w') as f:\n",
    "  json.dump(consts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "GcdRJC8uRYPx",
    "outputId": "edc31427-35f8-4c4b-d3b6-cd13ce5b414a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ressay/workspace/python/default/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ressay/workspace/python/default/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ressay/workspace/python/default/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "CONSTANTS_FILE_PATH = 'DialogueManager/FileBrowserDM/constants.json'\n",
    "constants_file = CONSTANTS_FILE_PATH\n",
    "\n",
    "with open(constants_file) as f:\n",
    "  constants = json.load(f)\n",
    "\n",
    "# Load run constants\n",
    "run_dict = constants['run']\n",
    "USE_USERSIM = run_dict['usersim']\n",
    "WARMUP_MEM = run_dict['warmup_mem']\n",
    "NUM_EP_TRAIN = run_dict['num_ep_run']\n",
    "TRAIN_FREQ = run_dict['train_freq']\n",
    "MAX_ROUND_NUM = run_dict['max_round_num']\n",
    "SUCCESS_RATE_THRESHOLD = run_dict['success_rate_threshold']\n",
    "compress = True\n",
    "train_batch = True\n",
    "use_encoder = False\n",
    "one_hot = True\n",
    "\n",
    "# Init. Objects\n",
    "user = UserSimulatorFB(constants,fbrowser.graph)\n",
    "\n",
    "dqn_agent = AgentFB(50, constants,train_batch, use_encoder, compress,one_hot)\n",
    "error_infuser = ErrorModelController(constants)\n",
    "all_actions = []\n",
    "all_trees = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7Ic7bWpSCAn"
   },
   "outputs": [],
   "source": [
    "def rm_keys(action):\n",
    "    a = {}\n",
    "    for key in ['intent', 'file_name', 'slot', 'new_directory', 'path', 'origin', 'dest']:\n",
    "        if key in action:\n",
    "            a[key] = action[key]\n",
    "    return a\n",
    "            \n",
    "\n",
    "def run_round(user):\n",
    "    # 1) Agent takes action given state tracker's representation of dialogue (state)\n",
    "#     print('running round')\n",
    "#     user.state['current_file_tree'].print_tree()\n",
    "#     dqn_agent.state_tracker.get_data()['current_tree_sim'].print_tree()\n",
    "    state = dqn_agent.get_state()\n",
    "    \n",
    "    try:\n",
    "        agent_action_index, agent_action = dqn_agent.step()\n",
    "        user_action, reward, done, success = user.step(agent_action)\n",
    "        error_infuser.infuse_error(user_action)\n",
    "        dqn_agent.update_state_user_action(user_action)\n",
    "    except Exception as e:\n",
    "        user.state['current_file_tree'].print_tree()\n",
    "        dqn_agent.state_tracker.get_data()['current_tree_sim'].print_tree()\n",
    "        for acts,trees in zip(all_actions,all_trees):\n",
    "            u, a = acts\n",
    "            u = rm_keys(u)\n",
    "            a = rm_keys(a)\n",
    "            print(u)\n",
    "            print(a)\n",
    "            t1,t2 = trees\n",
    "            t1.print_tree()\n",
    "            t2.print_tree()\n",
    "        raise e\n",
    "    \n",
    "\n",
    "        \n",
    "    # if not done:\n",
    "        # 4) Infuse error into semantic frame level of user action\n",
    "        # emc.infuse_error(user_action)\n",
    "    # 5) Update state tracker with user action\n",
    "    \n",
    "    \n",
    "    all_actions.append((agent_action, user_action))\n",
    "    all_trees.append((user.state['current_file_tree'].copy(),\n",
    "                    dqn_agent.state_tracker.get_data()['current_tree_sim'].copy()))\n",
    "    tuser1, tagent2 = all_trees[-1]\n",
    "    f, t = tuser1.tree_similarity(tagent2)\n",
    "    if f != t and user_action['intent'] != 'end':\n",
    "        print('not similar! ', f, t)\n",
    "        print('prev:')\n",
    "        tt1, tt2 = all_trees[-2]\n",
    "        tt1.print_tree()\n",
    "        tt2.print_tree()\n",
    "        print(tt1.tree_map)\n",
    "        print(tt2.tree_map)\n",
    "        a, u = all_actions[-1]\n",
    "        u = rm_keys(u)\n",
    "        a = rm_keys(a)\n",
    "        print(a)\n",
    "        print(u)\n",
    "        tuser1.print_tree()\n",
    "        tagent2.print_tree()\n",
    "        print(tuser1.tree_map)\n",
    "        print(tagent2.tree_map)\n",
    "        print('all_actions:', len(all_actions))\n",
    "        for a, u in all_actions:\n",
    "            u = rm_keys(u)\n",
    "            a = rm_keys(a)\n",
    "            print(a)\n",
    "            print(u)\n",
    "    # state_tracker.update_state_user(user_action)\n",
    "    # 6) Get next state and add experience\n",
    "    next_state = dqn_agent.get_state()\n",
    "    # next_state = state_tracker.get_state(done)\n",
    "    dqn_agent.add_experience(state, agent_action_index, reward, next_state, done)\n",
    "\n",
    "    return reward, done, success\n",
    "\n",
    "\n",
    "def train_run():\n",
    "    \"\"\"\n",
    "    Runs the loop that trains the agent.\n",
    "    Trains the agent on the goal-oriented chatbot task. Training of the agent's neural network occurs every episode that\n",
    "    TRAIN_FREQ is a multiple of. Terminates when the episode reaches NUM_EP_TRAIN.\n",
    "    \"\"\"\n",
    "    print('Training Started...')\n",
    "    \n",
    "    success_rate_best = 0.95\n",
    "    episode = 0\n",
    "    avg_tree_size_succeeded = 0.0\n",
    "    tree_sizes = []\n",
    "    ftree_sizes = []\n",
    "    period_reward_total = 0\n",
    "    period_reward_success = 0\n",
    "    period_success_total = 0      \n",
    "    while episode < NUM_EP_TRAIN:\n",
    "        user = episode_reset()\n",
    "        episode += 1\n",
    "        # print('running episode:',episode)\n",
    "        done = False\n",
    "        # state = state_tracker.get_state()\n",
    "        r_sum = 0\n",
    "        while not done:\n",
    "            reward, done, success = run_round(user)\n",
    "            period_reward_total += reward\n",
    "            r_sum += reward\n",
    "              \n",
    "\n",
    "        # print('success is: ',success)\n",
    "        period_success_total += success\n",
    "        period_reward_success += r_sum*success\n",
    "        rsize = user.goal['goal_tree'].r_size()\n",
    "        if success == 1:\n",
    "          tree_sizes.append(rsize)\n",
    "        else:\n",
    "          ftree_sizes.append(rsize)\n",
    "\n",
    "        # Train\n",
    "        if episode % TRAIN_FREQ == 0:\n",
    "\n",
    "            # Check success rate\n",
    "            success_rate = period_success_total / TRAIN_FREQ\n",
    "            avg_reward = period_reward_total / TRAIN_FREQ\n",
    "            avg_success_reward = period_reward_success / max((period_success_total,1))\n",
    "            if not len(tree_sizes): tree_sizes = [1]\n",
    "            if not len(ftree_sizes): ftree_sizes = [1]\n",
    "            print('training after getting success_rate:', success_rate, \" and avg_reward: \",avg_reward, \" avg success reward \", avg_success_reward,\n",
    "                  \" max tree size: \",max(tree_sizes),\" avg size: \",float(sum(tree_sizes))/max((1,len(tree_sizes))),\n",
    "                  \" avg failure size: \", float(sum(ftree_sizes))/max((1,len(ftree_sizes))), \" min failure size: \",min(ftree_sizes))\n",
    "            \n",
    "            # Update current best success rate\n",
    "            \n",
    "            # Flush\n",
    "#             if success_rate > success_rate_best and success_rate >= SUCCESS_RATE_THRESHOLD:\n",
    "#                 dqn_agent.empty_memory()\n",
    "#                 period_reward_total = 0\n",
    "#                 period_success_total = 0\n",
    "#                 period_reward_success = 0\n",
    "#                 avg_tree_size_succeeded = 0.0\n",
    "#                 tree_sizes = []\n",
    "#                 success_rate_best = success_rate\n",
    "#                 dqn_agent.save_weights()\n",
    "#                 continue\n",
    "#             period_success_total = 0\n",
    "#             period_reward_total = 0\n",
    "            if success_rate > success_rate_best:\n",
    "                # print('Episode: {} NEW BEST SUCCESS RATE: {} Avg Reward: {}' .format(episode, success_rate, avg_reward))\n",
    "                success_rate_best = success_rate\n",
    "                dqn_agent.save_weights()\n",
    "#                 uploaded = drive.CreateFile({'title': 'm_beh.h5'})\n",
    "#                 uploaded.SetContentFile('my_weights/m_beh.h5')\n",
    "#                 uploaded.Upload()\n",
    "#                 print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
    "          \n",
    "            period_reward_total = 0\n",
    "            period_success_total = 0\n",
    "            period_reward_success = 0\n",
    "            avg_tree_size_succeeded = 0.0\n",
    "            tree_sizes = []\n",
    "            ftree_sizes = []\n",
    "            # Copy\n",
    "            dqn_agent.copy()\n",
    "            # Train\n",
    "            dqn_agent.train()\n",
    "            \n",
    "    print('...Training Ended')\n",
    "\n",
    "\n",
    "def episode_reset():\n",
    "    \"\"\"\n",
    "    Resets the episode/conversation in the warmup and training loops.\n",
    "    Called in warmup and train to reset the state tracker, user and agent. Also gets the initial user action.\n",
    "    \"\"\"\n",
    "#     user = UserSimulatorFB(constants,fbrowser.graph)\n",
    "    all_actions.clear()\n",
    "    all_trees.clear()\n",
    "    tree_sim = FileTreeSimulator()\n",
    "    data = {'current_tree_sim': tree_sim, 'tree_sim': tree_sim}\n",
    "    user_action = user.reset(data)\n",
    "    dqn_agent.reset(user_action,data)\n",
    "    all_trees.append((user.state['current_file_tree'].copy(),\n",
    "                          dqn_agent.state_tracker.get_data()['current_tree_sim'].copy()))\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCu07GJcE6qj"
   },
   "outputs": [],
   "source": [
    "dqn_agent.get_state_output = dqn_agent._build_state_model(dqn_agent.beh_model)\n",
    "dqn_agent.get_state_and_action = dqn_agent._built_state_action_model(dqn_agent.beh_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNKlX53HENSn"
   },
   "outputs": [],
   "source": [
    "dqn_agent.eps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "colab_type": "code",
    "id": "4ox2vx4eSFI2",
    "outputId": "94123b84-2bfa-4d58-add2-261848e9f4ad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started...\n",
      "training after getting success_rate: 0.02  and avg_reward:  -6.695  avg success reward  -2.0  max tree size:  5  avg size:  3.5  avg failure size:  6.244897959183674  min failure size:  1\n",
      "Epoch 1/1\n",
      "178/178 [==============================] - 15s 87ms/step - loss: 0.3528\n",
      "finished fitting on  2508  samples and avg triplet number:  54.16945773524721\n",
      "out candidates\n",
      "out dest\n",
      "out dest\n",
      "out dest\n",
      "out dest\n",
      "training after getting success_rate: 0.41  and avg_reward:  -0.525  avg success reward  2.7439024390243905  max tree size:  9  avg size:  4.634146341463414  avg failure size:  8.0  min failure size:  2\n",
      "Epoch 1/1\n",
      "304/304 [==============================] - 42s 139ms/step - loss: 0.6277\n",
      "finished fitting on  5200  samples and avg triplet number:  65.83096153846154\n",
      "training after getting success_rate: 0.22  and avg_reward:  -2.8  avg success reward  2.590909090909091  max tree size:  7  avg size:  4.0  avg failure size:  6.961538461538462  min failure size:  2\n",
      "Epoch 1/1\n",
      " 36/328 [==>...........................] - ETA: 47s - loss: 0.5391"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-71c04ae1d8c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-48db4fbb72cf>\u001b[0m in \u001b[0;36mtrain_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mdqn_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mdqn_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'...Training Ended'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/PFEM2/DialogueBot/DialogueManager/agent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_triplets_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         self.beh_model.fit_generator(train_gen(), epochs=1,\n\u001b[0;32m--> 544\u001b[0;31m                                      verbose=1, steps_per_epoch=int(num_batches))\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_triplets_sample\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples_trained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_graph_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/default/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/default/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/default/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/default/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "B6RYr1hmi_gI",
    "outputId": "cdaf8c6c-b6ad-4490-9163-b6d7e8614d02"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5IaCWLxjBml"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "do6ppLcvjFmJ",
    "outputId": "9b37997d-6d67-40a8-f23c-203928b5a1ad"
   },
   "outputs": [],
   "source": [
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': 'm_beh.h5'})\n",
    "uploaded.SetContentFile('my_weights/m_beh.h5')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHO3GTH3j-C7"
   },
   "outputs": [],
   "source": [
    "id='18eWGaUMTpqrnjSojPEUZwJp0Vq_UrgAS'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('my_weights/m_beh.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_str(action):\n",
    "    newa = {}\n",
    "    for k in action:\n",
    "        if k not in ['file_node','action_node']:\n",
    "            newa[k] = action[k]\n",
    "    return newa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWPdJloFlza2"
   },
   "outputs": [],
   "source": [
    "nlg_sys = Nlg_system()\n",
    "def simulate():\n",
    "    tree_sim = FileTreeSimulator()\n",
    "    data = {'current_tree_sim': tree_sim, 'tree_sim': tree_sim}\n",
    "    done = False\n",
    "    user_action = user.reset(data)\n",
    "    print('user goal:')\n",
    "    tree_sim.print_tree()\n",
    "    user.goal['goal_tree'].print_tree()\n",
    "    print('user: ', user_action)\n",
    "    \n",
    "    dqn_agent.reset(user_action,data)\n",
    "    while not done:\n",
    "        agent_action_index, agent_action = dqn_agent.step()\n",
    "        print('agent: ',nlg_sys.get_sentence(agent_action))\n",
    "        user_action, reward, done, success = user.step(agent_action)\n",
    "        print('user: ', user_action)\n",
    "        dqn_agent.update_state_user_action(user_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_agent.eps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "ZmDebEfBl3sa",
    "outputId": "507b2f03-e1b3-451c-e72c-2c7d8423081d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [1,2,3] \n",
    "y1 = [2,2,1] \n",
    "# plotting the line 1 points  \n",
    "plt.plot(x1, y1, label = \"line 1\") \n",
    "  \n",
    "# line 2 points \n",
    "x2 = [1,2,3] \n",
    "y2 = [4,3,3] \n",
    "# plotting the line 2 points  \n",
    "plt.plot(x2, y2, label = \"line 2\") \n",
    "  \n",
    "# naming the x axis \n",
    "plt.xlabel('x - axis') \n",
    "# naming the y axis \n",
    "plt.ylabel('y - axis') \n",
    "# giving a title to my graph \n",
    "plt.title('Two lines on same graph!') \n",
    "  \n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "  \n",
    "# function to show the plot \n",
    "# plt.show() \n",
    "plt.savefig('foo.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = [1,2,3]\n",
    "success_rate = [0.1,0.4,0.6]\n",
    "avg_reward = [1,4,10]\n",
    "data = {\n",
    "    'episodes': episodes,\n",
    "    'success_rate': success_rate,\n",
    "    'avg_reward': avg_reward\n",
    "}\n",
    "newpd = pd.DataFrame(data=data)\n",
    "newpd.to_csv('file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
