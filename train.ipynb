{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "colab_type": "code",
    "id": "GOF52wJl6FbB",
    "outputId": "9323455d-4229-4d71-ac60-0038263eac1c"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "Mo5LdP5n67az",
    "outputId": "ca4144ba-f0eb-41a4-a72e-bbc433ac30ee"
   },
   "outputs": [],
   "source": [
    "!rm -r DialogueBot\n",
    "!git clone https://github.com/ressay/DialogueBot.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "figYChXmedwB",
    "outputId": "747e50d1-fbf8-44c5-8980-ec95b56ab46c"
   },
   "outputs": [],
   "source": [
    "!pip install rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkgVGk_E88LU"
   },
   "outputs": [],
   "source": [
    "!pip install -r DialogueBot/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWcbV_bTW62g"
   },
   "outputs": [],
   "source": [
    "!mkdir my_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ETRIk7eJ-_jh",
    "outputId": "7209a3a0-0b66-4c7f-b522-f997d09cb57c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \".\")\n",
    "from DialogueManager.FileBrowserDM.agent import AgentFB\n",
    "from DialogueManager.FileBrowserDM.user_simulator import UserSimulatorFB\n",
    "import Ontologies.onto_fbrowser as fbrowser\n",
    "import argparse, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hk9D15dGTmDp"
   },
   "outputs": [],
   "source": [
    "CONSTANTS_FILE_PATH = 'DialogueManager/FileBrowserDM/constants.json'\n",
    "constants_file = CONSTANTS_FILE_PATH\n",
    "\n",
    "consts = {\n",
    "  \"run\": {\n",
    "    \"usersim\": True,\n",
    "    \"warmup_mem\": 1000,\n",
    "    \"num_ep_run\": 40000,\n",
    "    \"train_freq\": 100,\n",
    "    \"max_round_num\": 40,\n",
    "    \"success_rate_threshold\": 0.3\n",
    "  },\n",
    "  \"agent\": {\n",
    "    \"save_weights_file_path\": \"my_weights/m_encoder.h5\",\n",
    "    \"load_weights_file_path\": 0,\n",
    "    \"vanilla\": True,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 128,\n",
    "    \"dqn_hidden_size\": 80,\n",
    "    \"epsilon_init\": 0.7,\n",
    "    \"gamma\": 0.7,\n",
    "    \"max_mem_size\": 50000,\n",
    "    \"agent_actions\": [\"Create_file\",\"Delete_file\",\"Change_directory\",\n",
    "      \"inform\",\"ask\",\"request\"]\n",
    "  },\n",
    "  \"emc\": {\n",
    "    \"slot_error_mode\": 0,\n",
    "    \"slot_error_prob\": 0.05,\n",
    "    \"intent_error_prob\": 0.0\n",
    "  }\n",
    "}\n",
    "with open(constants_file, 'w') as f:\n",
    "  json.dump(consts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "GcdRJC8uRYPx",
    "outputId": "edc31427-35f8-4c4b-d3b6-cd13ce5b414a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ressay/workspace/python/default/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ressay/workspace/python/default/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ressay/workspace/python/default/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "CONSTANTS_FILE_PATH = 'DialogueManager/FileBrowserDM/constants.json'\n",
    "constants_file = CONSTANTS_FILE_PATH\n",
    "\n",
    "with open(constants_file) as f:\n",
    "  constants = json.load(f)\n",
    "\n",
    "# Load run constants\n",
    "run_dict = constants['run']\n",
    "USE_USERSIM = run_dict['usersim']\n",
    "WARMUP_MEM = run_dict['warmup_mem']\n",
    "NUM_EP_TRAIN = run_dict['num_ep_run']\n",
    "TRAIN_FREQ = run_dict['train_freq']\n",
    "MAX_ROUND_NUM = run_dict['max_round_num']\n",
    "SUCCESS_RATE_THRESHOLD = run_dict['success_rate_threshold']\n",
    "compress = True\n",
    "train_batch = True\n",
    "use_encoder = True\n",
    "one_hot = True\n",
    "\n",
    "# Init. Objects\n",
    "user = UserSimulatorFB(constants,fbrowser.graph)\n",
    "\n",
    "dqn_agent = AgentFB(1024, constants,train_batch, use_encoder, compress,one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7Ic7bWpSCAn"
   },
   "outputs": [],
   "source": [
    "def run_round(user):\n",
    "    # 1) Agent takes action given state tracker's representation of dialogue (state)\n",
    "    state = dqn_agent.get_state()\n",
    "    agent_action_index, agent_action = dqn_agent.step()\n",
    "    user_action, reward, done, success = user.step(agent_action)\n",
    "    # if not done:\n",
    "        # 4) Infuse error into semantic frame level of user action\n",
    "        # emc.infuse_error(user_action)\n",
    "    # 5) Update state tracker with user action\n",
    "    dqn_agent.update_state_user_action(user_action)\n",
    "    # state_tracker.update_state_user(user_action)\n",
    "    # 6) Get next state and add experience\n",
    "    next_state = dqn_agent.get_state()\n",
    "    # next_state = state_tracker.get_state(done)\n",
    "    dqn_agent.add_experience(state, agent_action_index, reward, next_state, done)\n",
    "\n",
    "    return reward, done, success\n",
    "\n",
    "\n",
    "def train_run():\n",
    "    \"\"\"\n",
    "    Runs the loop that trains the agent.\n",
    "    Trains the agent on the goal-oriented chatbot task. Training of the agent's neural network occurs every episode that\n",
    "    TRAIN_FREQ is a multiple of. Terminates when the episode reaches NUM_EP_TRAIN.\n",
    "    \"\"\"\n",
    "    print('Training Started...')\n",
    "    \n",
    "    success_rate_best = 0.0\n",
    "    episode = 0\n",
    "    avg_tree_size_succeeded = 0.0\n",
    "    tree_sizes = []\n",
    "    ftree_sizes = []\n",
    "    period_reward_total = 0\n",
    "    period_reward_success = 0\n",
    "    period_success_total = 0      \n",
    "    while episode < NUM_EP_TRAIN:\n",
    "        user = episode_reset()\n",
    "        episode += 1\n",
    "        # print('running episode:',episode)\n",
    "        done = False\n",
    "        # state = state_tracker.get_state()\n",
    "        r_sum = 0\n",
    "        while not done:\n",
    "            reward, done, success = run_round(user)\n",
    "            period_reward_total += reward\n",
    "            r_sum += reward\n",
    "              \n",
    "\n",
    "        # print('success is: ',success)\n",
    "        period_success_total += success\n",
    "        period_reward_success += r_sum*success\n",
    "        rsize = user.goal['goal_tree'].r_size()\n",
    "        if success == 1:\n",
    "          tree_sizes.append(rsize)\n",
    "        else:\n",
    "          ftree_sizes.append(rsize)\n",
    "\n",
    "        # Train\n",
    "        if episode % TRAIN_FREQ == 0:\n",
    "\n",
    "            # Check success rate\n",
    "            success_rate = period_success_total / TRAIN_FREQ\n",
    "            avg_reward = period_reward_total / TRAIN_FREQ\n",
    "            avg_success_reward = period_reward_success / max((period_success_total,1))\n",
    "            if not len(tree_sizes): tree_sizes = [1]\n",
    "            if not len(ftree_sizes): ftree_sizes = [1]\n",
    "            print('training after getting success_rate:', success_rate, \" and avg_reward: \",avg_reward, \" avg success reward \", avg_success_reward,\n",
    "                  \" max tree size: \",max(tree_sizes),\" avg size: \",float(sum(tree_sizes))/max((1,len(tree_sizes))),\n",
    "                  \" avg failure size: \", float(sum(ftree_sizes))/max((1,len(ftree_sizes))), \" min failure size: \",min(ftree_sizes))\n",
    "            \n",
    "            # Update current best success rate\n",
    "            \n",
    "            # Flush\n",
    "#             if success_rate > success_rate_best and success_rate >= SUCCESS_RATE_THRESHOLD:\n",
    "#                 dqn_agent.empty_memory()\n",
    "#                 period_reward_total = 0\n",
    "#                 period_success_total = 0\n",
    "#                 period_reward_success = 0\n",
    "#                 avg_tree_size_succeeded = 0.0\n",
    "#                 tree_sizes = []\n",
    "#                 success_rate_best = success_rate\n",
    "#                 dqn_agent.save_weights()\n",
    "#                 continue\n",
    "#             period_success_total = 0\n",
    "#             period_reward_total = 0\n",
    "            if success_rate > success_rate_best:\n",
    "                # print('Episode: {} NEW BEST SUCCESS RATE: {} Avg Reward: {}' .format(episode, success_rate, avg_reward))\n",
    "                success_rate_best = success_rate\n",
    "                dqn_agent.save_weights()\n",
    "#                 uploaded = drive.CreateFile({'title': 'm_beh.h5'})\n",
    "#                 uploaded.SetContentFile('my_weights/m_beh.h5')\n",
    "#                 uploaded.Upload()\n",
    "#                 print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
    "          \n",
    "            period_reward_total = 0\n",
    "            period_success_total = 0\n",
    "            period_reward_success = 0\n",
    "            avg_tree_size_succeeded = 0.0\n",
    "            tree_sizes = []\n",
    "            ftree_sizes = []\n",
    "            # Copy\n",
    "            dqn_agent.copy()\n",
    "            # Train\n",
    "            dqn_agent.train()\n",
    "            \n",
    "    print('...Training Ended')\n",
    "\n",
    "\n",
    "def episode_reset():\n",
    "    \"\"\"\n",
    "    Resets the episode/conversation in the warmup and training loops.\n",
    "    Called in warmup and train to reset the state tracker, user and agent. Also gets the initial user action.\n",
    "    \"\"\"\n",
    "#     user = UserSimulatorFB(constants,fbrowser.graph)\n",
    "    user_action = user.reset()\n",
    "    dqn_agent.reset(user_action)\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCu07GJcE6qj"
   },
   "outputs": [],
   "source": [
    "dqn_agent.get_state_output = dqn_agent._build_state_model(dqn_agent.beh_model)\n",
    "dqn_agent.get_state_and_action = dqn_agent._built_state_action_model(dqn_agent.beh_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNKlX53HENSn"
   },
   "outputs": [],
   "source": [
    "dqn_agent.eps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "colab_type": "code",
    "id": "4ox2vx4eSFI2",
    "outputId": "94123b84-2bfa-4d58-add2-261848e9f4ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started...\n",
      "ERROR HAPPENED AND IGNORING IT:  ('error from remove as ', AssertionError('dir3/ does not exist',))\n",
      "ERROR HAPPENED AND IGNORING IT:  ('error from remove as ', AssertionError('dir4/ does not exist',))\n",
      "training after getting success_rate: 0.19  and avg_reward:  -6.3  avg success reward  1.894736842105263  max tree size:  3  avg size:  1.4736842105263157  avg failure size:  4.666666666666667  min failure size:  1\n",
      "Epoch 1/1\n",
      "15/15 [==============================] - 10s 642ms/step - loss: 18.3445\n",
      "finished fitting on  1196  samples and avg triplet number:  0.0\n",
      "ERROR HAPPENED AND IGNORING IT:  ('error from remove as ', AssertionError('dir3/ does not exist',))\n",
      "ERROR HAPPENED AND IGNORING IT:  ('error from remove as ', AssertionError('dir2/ does not exist',))\n",
      "training after getting success_rate: 0.07  and avg_reward:  -8.075  avg success reward  0.8571428571428571  max tree size:  2  avg size:  1.1428571428571428  avg failure size:  4.21505376344086  min failure size:  1\n",
      "Epoch 1/1\n",
      "31/31 [==============================] - 23s 743ms/step - loss: 0.1616\n",
      "finished fitting on  2349  samples and avg triplet number:  0.0\n",
      "ERROR HAPPENED AND IGNORING IT:  ('error from remove as ', AssertionError('dir3/dir1/ does not exist',))\n",
      "ERROR HAPPENED AND IGNORING IT:  ('error from remove as ', AssertionError('dir3/dir1/ does not exist',))\n",
      "ERROR HAPPENED AND IGNORING IT:  ('error from remove as ', AssertionError('dir2/ does not exist',))\n",
      "training after getting success_rate: 0.15  and avg_reward:  -6.695  avg success reward  1.6666666666666667  max tree size:  3  avg size:  1.6666666666666667  avg failure size:  4.3882352941176475  min failure size:  1\n",
      "Epoch 1/1\n",
      " 4/46 [=>............................] - ETA: 28s - loss: 0.1433"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-71c04ae1d8c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-b73f14a2dd21>\u001b[0m in \u001b[0;36mtrain_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mdqn_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdqn_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'...Training Ended'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/PFEM2/DialogueBot/DialogueManager/agent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_triplets_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         self.beh_model.fit_generator(train_gen(), epochs=1,\n\u001b[0;32m--> 515\u001b[0;31m                                      verbose=1, steps_per_epoch=int(num_batches))\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_triplets_sample\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples_trained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_graph_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/default/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/default/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/default/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/default/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "B6RYr1hmi_gI",
    "outputId": "cdaf8c6c-b6ad-4490-9163-b6d7e8614d02"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5IaCWLxjBml"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "do6ppLcvjFmJ",
    "outputId": "9b37997d-6d67-40a8-f23c-203928b5a1ad"
   },
   "outputs": [],
   "source": [
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': 'm_beh.h5'})\n",
    "uploaded.SetContentFile('my_weights/m_beh.h5')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHO3GTH3j-C7"
   },
   "outputs": [],
   "source": [
    "id='18eWGaUMTpqrnjSojPEUZwJp0Vq_UrgAS'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('my_weights/m_beh.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWPdJloFlza2"
   },
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    done = False\n",
    "    user_action = user.reset()\n",
    "    print('user goal:')\n",
    "    user.goal['goal_tree'].print_tree()\n",
    "    print('user: ', user_action)\n",
    "    dqn_agent.reset(user_action)\n",
    "    while not done:\n",
    "        agent_action_index, agent_action = dqn_agent.step()\n",
    "        print('agent: ',agent_action)\n",
    "        user_action, reward, done, success = user.step(agent_action)\n",
    "        print('user: ', user_action)\n",
    "        dqn_agent.update_state_user_action(user_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "ZmDebEfBl3sa",
    "outputId": "507b2f03-e1b3-451c-e72c-2c7d8423081d"
   },
   "outputs": [],
   "source": [
    "simulate()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
