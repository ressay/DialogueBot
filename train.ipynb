{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "colab_type": "code",
    "id": "GOF52wJl6FbB",
    "outputId": "9323455d-4229-4d71-ac60-0038263eac1c"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "Mo5LdP5n67az",
    "outputId": "ca4144ba-f0eb-41a4-a72e-bbc433ac30ee"
   },
   "outputs": [],
   "source": [
    "!rm -r DialogueBot\n",
    "!git clone https://github.com/ressay/DialogueBot.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "figYChXmedwB",
    "outputId": "747e50d1-fbf8-44c5-8980-ec95b56ab46c"
   },
   "outputs": [],
   "source": [
    "!pip install rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkgVGk_E88LU"
   },
   "outputs": [],
   "source": [
    "!pip install -r DialogueBot/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWcbV_bTW62g"
   },
   "outputs": [],
   "source": [
    "!mkdir my_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ETRIk7eJ-_jh",
    "outputId": "7209a3a0-0b66-4c7f-b522-f997d09cb57c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \".\")\n",
    "from DialogueManager.FileBrowserDM.agent import AgentFB\n",
    "from DialogueManager.FileBrowserDM.user_simulator import UserSimulatorFB\n",
    "from DialogueManager.FileBrowserDM.file_tree_sim import FileTreeSimulator\n",
    "import Ontologies.onto_fbrowser as fbrowser\n",
    "import argparse, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hk9D15dGTmDp"
   },
   "outputs": [],
   "source": [
    "CONSTANTS_FILE_PATH = 'DialogueManager/FileBrowserDM/constants.json'\n",
    "constants_file = CONSTANTS_FILE_PATH\n",
    "\n",
    "consts = {\n",
    "  \"run\": {\n",
    "    \"usersim\": True,\n",
    "    \"warmup_mem\": 1000,\n",
    "    \"num_ep_run\": 40000,\n",
    "    \"train_freq\": 100,\n",
    "    \"max_round_num\": 40,\n",
    "    \"success_rate_threshold\": 0.3\n",
    "  },\n",
    "  \"agent\": {\n",
    "    \"save_weights_file_path\": \"my_weights/m.h5\",\n",
    "    \"load_weights_file_path\": \"my_weights/m2.h5\",\n",
    "    \"vanilla\": True,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 128,\n",
    "    \"dqn_hidden_size\": 80,\n",
    "    \"epsilon_init\": 0.3,\n",
    "    \"gamma\": 0.7,\n",
    "    \"max_mem_size\": 50000,\n",
    "    \"agent_actions\": [\"Create_file\",\"Delete_file\",\"Change_directory\",\n",
    "      \"inform\",\"ask\",\"request\"]\n",
    "  },\n",
    "  \"emc\": {\n",
    "    \"slot_error_mode\": 0,\n",
    "    \"slot_error_prob\": 0.05,\n",
    "    \"intent_error_prob\": 0.0\n",
    "  }\n",
    "}\n",
    "with open(constants_file, 'w') as f:\n",
    "  json.dump(consts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "GcdRJC8uRYPx",
    "outputId": "edc31427-35f8-4c4b-d3b6-cd13ce5b414a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ressay/workspace/python/default/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ressay/workspace/python/default/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ressay/workspace/python/default/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "CONSTANTS_FILE_PATH = 'DialogueManager/FileBrowserDM/constants.json'\n",
    "constants_file = CONSTANTS_FILE_PATH\n",
    "\n",
    "with open(constants_file) as f:\n",
    "  constants = json.load(f)\n",
    "\n",
    "# Load run constants\n",
    "run_dict = constants['run']\n",
    "USE_USERSIM = run_dict['usersim']\n",
    "WARMUP_MEM = run_dict['warmup_mem']\n",
    "NUM_EP_TRAIN = run_dict['num_ep_run']\n",
    "TRAIN_FREQ = run_dict['train_freq']\n",
    "MAX_ROUND_NUM = run_dict['max_round_num']\n",
    "SUCCESS_RATE_THRESHOLD = run_dict['success_rate_threshold']\n",
    "compress = True\n",
    "train_batch = True\n",
    "use_encoder = False\n",
    "one_hot = True\n",
    "\n",
    "# Init. Objects\n",
    "user = UserSimulatorFB(constants,fbrowser.graph)\n",
    "\n",
    "dqn_agent = AgentFB(650, constants,train_batch, use_encoder, compress,one_hot)\n",
    "all_actions = []\n",
    "all_trees = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7Ic7bWpSCAn"
   },
   "outputs": [],
   "source": [
    "def rm_keys(action):\n",
    "    a = {}\n",
    "    for key in ['intent', 'file_name', 'slot', 'new_directory', 'path', 'origin', 'dest']:\n",
    "        if key in action:\n",
    "            a[key] = action[key]\n",
    "    return a\n",
    "            \n",
    "\n",
    "def run_round(user):\n",
    "    # 1) Agent takes action given state tracker's representation of dialogue (state)\n",
    "#     print('running round')\n",
    "#     user.state['current_file_tree'].print_tree()\n",
    "#     dqn_agent.state_tracker.get_data()['current_tree_sim'].print_tree()\n",
    "    state = dqn_agent.get_state()\n",
    "    agent_action_index, agent_action = dqn_agent.step()\n",
    "    try:\n",
    "        user_action, reward, done, success = user.step(agent_action)\n",
    "    except Exception as e:\n",
    "        user.state['current_file_tree'].print_tree()\n",
    "        dqn_agent.state_tracker.get_data()['current_tree_sim'].print_tree()\n",
    "        for acts,trees in zip(all_actions,all_trees):\n",
    "            u, a = acts\n",
    "            u = rm_keys(u)\n",
    "            a = rm_keys(a)\n",
    "            print(a)\n",
    "            print(u)\n",
    "            t1,t2 = trees\n",
    "            t1.print_tree()\n",
    "            t2.print_tree()\n",
    "            \n",
    "        raise e\n",
    "    \n",
    "\n",
    "        \n",
    "    # if not done:\n",
    "        # 4) Infuse error into semantic frame level of user action\n",
    "        # emc.infuse_error(user_action)\n",
    "    # 5) Update state tracker with user action\n",
    "    dqn_agent.update_state_user_action(user_action)\n",
    "    \n",
    "    all_actions.append((agent_action, user_action))\n",
    "    all_trees.append((user.state['current_file_tree'].copy(),\n",
    "                    dqn_agent.state_tracker.get_data()['current_tree_sim'].copy()))\n",
    "    t1, t2 = all_trees[-1]\n",
    "    f, t = t1.tree_similarity(t2)\n",
    "    if f != t and user_action['intent'] != 'end':\n",
    "        print('not similar! ', f, t)\n",
    "        print('prev:')\n",
    "        tt1, tt2 = all_trees[-2]\n",
    "        tt1.print_tree()\n",
    "        tt2.print_tree()\n",
    "        print(tt1.tree_map)\n",
    "        print(tt2.tree_map)\n",
    "        a, u = all_actions[-1]\n",
    "        u = rm_keys(u)\n",
    "        a = rm_keys(a)\n",
    "        print(a)\n",
    "        print(u)\n",
    "        t1.print_tree()\n",
    "        t2.print_tree()\n",
    "        print(t1.tree_map)\n",
    "        print(t2.tree_map)\n",
    "        print('all_actions:', len(all_actions))\n",
    "        for a, u in all_actions:\n",
    "            u = rm_keys(u)\n",
    "            a = rm_keys(a)\n",
    "            print(a)\n",
    "            print(u)\n",
    "    # state_tracker.update_state_user(user_action)\n",
    "    # 6) Get next state and add experience\n",
    "    next_state = dqn_agent.get_state()\n",
    "    # next_state = state_tracker.get_state(done)\n",
    "    dqn_agent.add_experience(state, agent_action_index, reward, next_state, done)\n",
    "\n",
    "    return reward, done, success\n",
    "\n",
    "\n",
    "def train_run():\n",
    "    \"\"\"\n",
    "    Runs the loop that trains the agent.\n",
    "    Trains the agent on the goal-oriented chatbot task. Training of the agent's neural network occurs every episode that\n",
    "    TRAIN_FREQ is a multiple of. Terminates when the episode reaches NUM_EP_TRAIN.\n",
    "    \"\"\"\n",
    "    print('Training Started...')\n",
    "    \n",
    "    success_rate_best = 0.0\n",
    "    episode = 0\n",
    "    avg_tree_size_succeeded = 0.0\n",
    "    tree_sizes = []\n",
    "    ftree_sizes = []\n",
    "    period_reward_total = 0\n",
    "    period_reward_success = 0\n",
    "    period_success_total = 0      \n",
    "    while episode < NUM_EP_TRAIN:\n",
    "        user = episode_reset()\n",
    "        episode += 1\n",
    "        # print('running episode:',episode)\n",
    "        done = False\n",
    "        # state = state_tracker.get_state()\n",
    "        r_sum = 0\n",
    "        while not done:\n",
    "            reward, done, success = run_round(user)\n",
    "            period_reward_total += reward\n",
    "            r_sum += reward\n",
    "              \n",
    "\n",
    "        # print('success is: ',success)\n",
    "        period_success_total += success\n",
    "        period_reward_success += r_sum*success\n",
    "        rsize = user.goal['goal_tree'].r_size()\n",
    "        if success == 1:\n",
    "          tree_sizes.append(rsize)\n",
    "        else:\n",
    "          ftree_sizes.append(rsize)\n",
    "\n",
    "        # Train\n",
    "        if episode % TRAIN_FREQ == 0:\n",
    "\n",
    "            # Check success rate\n",
    "            success_rate = period_success_total / TRAIN_FREQ\n",
    "            avg_reward = period_reward_total / TRAIN_FREQ\n",
    "            avg_success_reward = period_reward_success / max((period_success_total,1))\n",
    "            if not len(tree_sizes): tree_sizes = [1]\n",
    "            if not len(ftree_sizes): ftree_sizes = [1]\n",
    "            print('training after getting success_rate:', success_rate, \" and avg_reward: \",avg_reward, \" avg success reward \", avg_success_reward,\n",
    "                  \" max tree size: \",max(tree_sizes),\" avg size: \",float(sum(tree_sizes))/max((1,len(tree_sizes))),\n",
    "                  \" avg failure size: \", float(sum(ftree_sizes))/max((1,len(ftree_sizes))), \" min failure size: \",min(ftree_sizes))\n",
    "            \n",
    "            # Update current best success rate\n",
    "            \n",
    "            # Flush\n",
    "#             if success_rate > success_rate_best and success_rate >= SUCCESS_RATE_THRESHOLD:\n",
    "#                 dqn_agent.empty_memory()\n",
    "#                 period_reward_total = 0\n",
    "#                 period_success_total = 0\n",
    "#                 period_reward_success = 0\n",
    "#                 avg_tree_size_succeeded = 0.0\n",
    "#                 tree_sizes = []\n",
    "#                 success_rate_best = success_rate\n",
    "#                 dqn_agent.save_weights()\n",
    "#                 continue\n",
    "#             period_success_total = 0\n",
    "#             period_reward_total = 0\n",
    "            if success_rate > success_rate_best:\n",
    "                # print('Episode: {} NEW BEST SUCCESS RATE: {} Avg Reward: {}' .format(episode, success_rate, avg_reward))\n",
    "                success_rate_best = success_rate\n",
    "                dqn_agent.save_weights()\n",
    "#                 uploaded = drive.CreateFile({'title': 'm_beh.h5'})\n",
    "#                 uploaded.SetContentFile('my_weights/m_beh.h5')\n",
    "#                 uploaded.Upload()\n",
    "#                 print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
    "          \n",
    "            period_reward_total = 0\n",
    "            period_success_total = 0\n",
    "            period_reward_success = 0\n",
    "            avg_tree_size_succeeded = 0.0\n",
    "            tree_sizes = []\n",
    "            ftree_sizes = []\n",
    "            # Copy\n",
    "            dqn_agent.copy()\n",
    "            # Train\n",
    "            dqn_agent.train()\n",
    "            \n",
    "    print('...Training Ended')\n",
    "\n",
    "\n",
    "def episode_reset():\n",
    "    \"\"\"\n",
    "    Resets the episode/conversation in the warmup and training loops.\n",
    "    Called in warmup and train to reset the state tracker, user and agent. Also gets the initial user action.\n",
    "    \"\"\"\n",
    "#     user = UserSimulatorFB(constants,fbrowser.graph)\n",
    "    all_actions.clear()\n",
    "    all_trees.clear()\n",
    "    tree_sim = FileTreeSimulator()\n",
    "    data = {'current_tree_sim': tree_sim, 'tree_sim': tree_sim}\n",
    "    user_action = user.reset(data)\n",
    "    dqn_agent.reset(user_action,data)\n",
    "    all_trees.append((user.state['current_file_tree'].copy(),\n",
    "                          dqn_agent.state_tracker.get_data()['current_tree_sim'].copy()))\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCu07GJcE6qj"
   },
   "outputs": [],
   "source": [
    "dqn_agent.get_state_output = dqn_agent._build_state_model(dqn_agent.beh_model)\n",
    "dqn_agent.get_state_and_action = dqn_agent._built_state_action_model(dqn_agent.beh_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNKlX53HENSn"
   },
   "outputs": [],
   "source": [
    "dqn_agent.eps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "colab_type": "code",
    "id": "4ox2vx4eSFI2",
    "outputId": "94123b84-2bfa-4d58-add2-261848e9f4ad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "B6RYr1hmi_gI",
    "outputId": "cdaf8c6c-b6ad-4490-9163-b6d7e8614d02"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5IaCWLxjBml"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "do6ppLcvjFmJ",
    "outputId": "9b37997d-6d67-40a8-f23c-203928b5a1ad"
   },
   "outputs": [],
   "source": [
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': 'm_beh.h5'})\n",
    "uploaded.SetContentFile('my_weights/m_beh.h5')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHO3GTH3j-C7"
   },
   "outputs": [],
   "source": [
    "id='18eWGaUMTpqrnjSojPEUZwJp0Vq_UrgAS'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('my_weights/m_beh.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_str(action):\n",
    "    newa = {}\n",
    "    for k in action:\n",
    "        if k not in ['file_node','action_node']:\n",
    "            newa[k] = action[k]\n",
    "    return newa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWPdJloFlza2"
   },
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    tree_sim = FileTreeSimulator()\n",
    "    data = {'current_tree_sim': tree_sim, 'tree_sim': tree_sim}\n",
    "    done = False\n",
    "    user_action = user.reset(data)\n",
    "    print('user goal:')\n",
    "    tree_sim.print_tree()\n",
    "    user.goal['goal_tree'].print_tree()\n",
    "    print('user: ', user_action)\n",
    "    \n",
    "    dqn_agent.reset(user_action,data)\n",
    "    while not done:\n",
    "        agent_action_index, agent_action = dqn_agent.step()\n",
    "        print('agent: ',agent_action)\n",
    "        user_action, reward, done, success = user.step(agent_action)\n",
    "        print('user: ', user_action)\n",
    "        dqn_agent.update_state_user_action(user_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_agent.eps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "ZmDebEfBl3sa",
    "outputId": "507b2f03-e1b3-451c-e72c-2c7d8423081d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user goal:\n",
      "~:\n",
      "-> file1\n",
      "-> file2\n",
      "~:\n",
      "-> file1\n",
      "-> file2\n",
      "-> dir1\n",
      "---> dir2\n",
      "---> file2\n",
      "---> dir3\n",
      "user:  {'intent': 'Create_file_desire', 'is_file': 0}\n",
      "agent:  {'intent': 'request', 'slot': 'file_name', 'file_node': rdflib.term.BNode('N63d9b378b71b43cbbce0b3aa40fd160a'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_request')}\n",
      "user:  {'intent': 'inform', 'file_name': 'dir1'}\n",
      "agent:  {'intent': 'request', 'slot': 'parent_directory', 'file_name': 'dir1', 'file_node': rdflib.term.BNode('N63d9b378b71b43cbbce0b3aa40fd160a'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_request')}\n",
      "user:  {'intent': 'inform', 'parent_directory': '~'}\n",
      "agent:  {'intent': 'Create_file', 'file_name': 'dir1', 'is_file': 0, 'path': '~/', 'file_node': rdflib.term.BNode('N63d9b378b71b43cbbce0b3aa40fd160a'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Create_file')}\n",
      "user:  {'intent': 'Change_directory_desire', 'directory': 'dir1'}\n",
      "agent:  {'intent': 'ask', 'action': {'intent': 'Change_directory', 'new_directory': '~/', 'file_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#root_directory'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Change_directory')}, 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_ask')}\n",
      "user:  {'intent': 'deny'}\n",
      "agent:  {'intent': 'ask', 'action': {'intent': 'Delete_file', 'file_name': 'dir1', 'path': '~/', 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Delete_file'), 'file_node': rdflib.term.BNode('N63d9b378b71b43cbbce0b3aa40fd160a')}, 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_ask')}\n",
      "user:  {'intent': 'deny'}\n",
      "agent:  {'intent': 'ask', 'action': {'intent': 'Change_directory', 'new_directory': '~/', 'file_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#root_directory'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Change_directory')}, 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_ask')}\n",
      "user:  {'intent': 'deny'}\n",
      "agent:  {'intent': 'Delete_file', 'file_name': 'file2', 'path': '~/', 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Delete_file'), 'file_node': rdflib.term.BNode('N92437e4769d44bdcad9b37ffe24eff79')}\n",
      "user:  {'intent': 'Change_directory_desire', 'directory': 'dir1'}\n",
      "agent:  {'intent': 'ask', 'action': {'intent': 'Change_directory', 'new_directory': '~/dir1', 'file_node': rdflib.term.BNode('N63d9b378b71b43cbbce0b3aa40fd160a'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Change_directory')}, 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_ask')}\n",
      "user:  {'intent': 'confirm'}\n",
      "agent:  {'intent': 'Change_directory', 'new_directory': '~/', 'file_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#root_directory'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Change_directory')}\n",
      "user:  {'intent': 'Change_directory_desire', 'directory': 'dir1'}\n",
      "agent:  {'intent': 'Change_directory', 'new_directory': '~/dir1', 'file_node': rdflib.term.BNode('N63d9b378b71b43cbbce0b3aa40fd160a'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Change_directory')}\n",
      "user:  {'intent': 'Move_file_desire'}\n",
      "agent:  {'intent': 'request', 'slot': 'file_name', 'file_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Move_file'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_request'), 'special': 'file_not_found'}\n",
      "user:  {'intent': 'inform', 'file_name': 'file1'}\n",
      "agent:  {'intent': 'Change_directory', 'new_directory': '~/', 'file_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#root_directory'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Change_directory')}\n",
      "user:  {'intent': 'Move_file_desire', 'dest': 'dir1', 'file_name': 'file1'}\n",
      "agent:  {'intent': 'ask', 'action': {'intent': 'Change_directory', 'new_directory': '~/', 'file_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#root_directory'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Change_directory')}, 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_ask')}\n",
      "user:  {'intent': 'deny'}\n",
      "agent:  {'intent': 'Move_file', 'file_name': 'file1', 'origin': '~/', 'dest': '~/dir1', 'action_node': rdflib.term.BNode('N63d9b378b71b43cbbce0b3aa40fd160a'), 'file_node': rdflib.term.BNode('N13318b712b5f48c0a7a92c187707beb9'), 'dest_node': rdflib.term.BNode('N63d9b378b71b43cbbce0b3aa40fd160a')}\n",
      "user:  {'intent': 'Delete_file_desire', 'file_name': 'file1', 'is_file': 1}\n",
      "agent:  {'intent': 'Delete_file', 'file_name': 'file1', 'path': '~/dir1/', 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Delete_file'), 'file_node': rdflib.term.BNode('N8dbe3b8e8694483b8ac0d45637112e42')}\n",
      "user:  {'intent': 'Change_directory_desire', 'directory': 'dir1'}\n",
      "agent:  {'intent': 'Change_directory', 'new_directory': '~/dir1', 'file_node': rdflib.term.BNode('N63d9b378b71b43cbbce0b3aa40fd160a'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Change_directory')}\n",
      "user:  {'intent': 'Create_file_desire', 'file_name': 'dir2', 'is_file': 0}\n",
      "agent:  {'intent': 'Create_file', 'file_name': 'dir2', 'is_file': 0, 'path': '~/dir1/', 'file_node': rdflib.term.BNode('N0fb71216914e4b6f99e248bc5cdb225a'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Create_file')}\n",
      "user:  {'intent': 'Create_file_desire', 'file_name': 'file2', 'is_file': 1}\n",
      "agent:  {'intent': 'Create_file', 'file_name': 'file2', 'is_file': 1, 'path': '~/dir1/', 'file_node': rdflib.term.BNode('Nf249099fb7804711b7bfca8180d4bc5d'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Create_file')}\n",
      "user:  {'intent': 'Create_file_desire', 'file_name': 'dir3', 'is_file': 0}\n",
      "agent:  {'intent': 'request', 'slot': 'parent_directory', 'file_name': 'dir3', 'file_node': rdflib.term.BNode('Nfff7ddaa1a424a7da135d04ec0c8730b'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_request')}\n",
      "user:  {'intent': 'inform', 'parent_directory': 'dir1'}\n",
      "agent:  {'intent': 'ask', 'action': {'intent': 'Change_directory', 'new_directory': '~/', 'file_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#root_directory'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Change_directory')}, 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_ask')}\n",
      "user:  {'intent': 'deny'}\n",
      "agent:  {'intent': 'request', 'slot': 'parent_directory', 'file_name': 'dir3', 'file_node': rdflib.term.BNode('Nfff7ddaa1a424a7da135d04ec0c8730b'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_request')}\n",
      "user:  {'intent': 'inform', 'parent_directory': 'dir1'}\n",
      "agent:  {'intent': 'request', 'slot': 'parent_directory', 'file_name': 'dir3', 'file_node': rdflib.term.BNode('Nfff7ddaa1a424a7da135d04ec0c8730b'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_request')}\n",
      "user:  {'intent': 'inform', 'parent_directory': 'dir1'}\n",
      "agent:  {'intent': 'request', 'slot': 'parent_directory', 'file_name': 'dir3', 'file_node': rdflib.term.BNode('Nfff7ddaa1a424a7da135d04ec0c8730b'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#A_request')}\n",
      "user:  {'intent': 'inform', 'parent_directory': 'dir1'}\n",
      "agent:  {'intent': 'Change_directory', 'new_directory': '~/', 'file_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#root_directory'), 'action_node': rdflib.term.URIRef('http://www.semanticweb.org/ressay/ontologies/2019/2/untitled-ontology-7#Change_directory')}\n",
      "user:  {'intent': 'end'}\n"
     ]
    }
   ],
   "source": [
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
