{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "8PdEXT9P4Zko",
    "outputId": "c4ef5359-23bd-4286-9609-c3c51dca52db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.9)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.7)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (40.9.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (0.15.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (3.1)\n",
      "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (2.0.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (5.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "6BxprsmL4Zk6",
    "outputId": "1edbb3ee-4a11-4902-b81c-920c47050daa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-a9V8aW4ZlE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ressay/workspace/tensorFlow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, GRU, LSTM, Dense, Conv2D, Reshape, MaxPool2D, Flatten, TimeDistributed\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K2epE_zL0tME"
   },
   "outputs": [],
   "source": [
    "def to_int_onehot(bitlist):\n",
    "    return np.argmax(bitlist)\n",
    "\n",
    "def to_int_integer(bitlist):\n",
    "    return bitlist[0]\n",
    "\n",
    "def to_int_binary(bitlist):\n",
    "    out = 0\n",
    "    for bit in bitlist:\n",
    "        bit = int(round(bit))\n",
    "        out = (out << 1) | bit\n",
    "    return out\n",
    "  \n",
    "def bin_array(num, m):\n",
    "    \"\"\"Convert a positive integer num into an m-bit bit vector\"\"\"\n",
    "    return np.array(list(np.binary_repr(num).zfill(m))).astype(np.int8)\n",
    "\n",
    "def integer_array(num, m):\n",
    "    \"\"\"Convert a positive integer num into an m-bit bit vector\"\"\"\n",
    "    return np.array([num])\n",
    "\n",
    "def onehot_array(num, m):\n",
    "    \"\"\"Convert a positive integer num into an m-bit bit vector\"\"\"\n",
    "    arr = np.zeros(m)\n",
    "    arr[num] = 1\n",
    "    return arr\n",
    "  \n",
    "def print_graphs(graphs):\n",
    "    for graph in graphs:\n",
    "        for triplet in graph:\n",
    "            s,p,o = triplet[:node_encoding_size],\\\n",
    "                    triplet[node_encoding_size:node_encoding_size+edge_encoding_size],\\\n",
    "                    triplet[-node_encoding_size:]\n",
    "            print(to_int(s),\":\",to_int(p),\":\",to_int(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CM1qulud4ZlU"
   },
   "outputs": [],
   "source": [
    "w = 32\n",
    "h = 32\n",
    "hidden_state_dim = w*h\n",
    "t = 1 # 0 for binary, 1 for one_hot, 2 for integers\n",
    "node_size = 9\n",
    "edge_size = 7\n",
    "if not t:\n",
    "    # each node is encoded in x bits\n",
    "    node_encoding_size = node_size\n",
    "    # each edge is encoded in x bits\n",
    "    edge_encoding_size = edge_size\n",
    "    m_node = 2**node_encoding_size\n",
    "    m_edge = 2**edge_encoding_size\n",
    "    to_int = to_int_binary\n",
    "    to_array = bin_array\n",
    "elif t == 1:\n",
    "    # each node is encoded in x bits\n",
    "    node_encoding_size = 2**node_size\n",
    "    # each edge is encoded in x bits\n",
    "    edge_encoding_size = 2**edge_size\n",
    "    m_node = node_encoding_size\n",
    "    m_edge = edge_encoding_size\n",
    "    to_int = to_int_onehot\n",
    "    to_array = onehot_array\n",
    "else:\n",
    "    node_encoding_size = 1\n",
    "    # each edge is encoded in x bits\n",
    "    edge_encoding_size = 1\n",
    "    m_node = 2**node_size\n",
    "    m_edge = 1**edge_size\n",
    "    to_int = to_int_integer\n",
    "    to_array = integer_array\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "# size is number of triplets, each triplet has 2 nodes and 1 edge\n",
    "triplet_size = node_encoding_size*2+edge_encoding_size\n",
    "\n",
    "graph_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqTeK3rkEjuY"
   },
   "outputs": [],
   "source": [
    "def compare(t1,t2):\n",
    "    for i in range(3):\n",
    "        if t1[i] < t2[i]:\n",
    "            return 1\n",
    "        if t1[i] > t2[i]:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "def partition(array, begin, end):\n",
    "    pivot = begin\n",
    "    for i in range(begin+1, end+1):\n",
    "        if compare(array[i],array[begin]) <= 0:\n",
    "            pivot += 1\n",
    "            array[i], array[pivot] = array[pivot], array[i]\n",
    "    array[pivot], array[begin] = array[begin], array[pivot]\n",
    "    return pivot\n",
    "\n",
    "\n",
    "\n",
    "def quicksort(array, begin=0, end=None):\n",
    "    if end is None:\n",
    "        end = len(array) - 1\n",
    "    def _quicksort(array, begin, end):\n",
    "        if begin >= end:\n",
    "            return\n",
    "        pivot = partition(array, begin, end)\n",
    "        _quicksort(array, begin, pivot-1)\n",
    "        _quicksort(array, pivot+1, end)\n",
    "    return _quicksort(array, begin, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0-73vQ14Zlh"
   },
   "outputs": [],
   "source": [
    "def random_graph_triples(size, nSize, eSize):\n",
    "    triplets = np.zeros((size, triplet_size))\n",
    "    num_n, num_e = max((2,size)),max((2,size))\n",
    "    possible_nodes = [int(random.uniform(1,nSize)) \n",
    "                      for i in range(num_n)]\n",
    "    possible_edges = [int(random.uniform(1,eSize)) \n",
    "                      for i in range(num_e)]\n",
    "    for i in range(size):\n",
    "        s = to_array(possible_nodes[int(random.uniform(0, num_n-1))],\n",
    "                     node_encoding_size)\n",
    "        o = to_array(possible_nodes[int(random.uniform(0, num_n-1))],\n",
    "                     node_encoding_size)\n",
    "        p = to_array(possible_edges[int(random.uniform(0, num_e-1))],\n",
    "                     edge_encoding_size)\n",
    "        triplets[i, :] = np.concatenate((s, p, o))\n",
    "    return triplets\n",
    "\n",
    "def random_graph_triples_ordered(size, nSize, eSize):\n",
    "    triplets = np.zeros((size, triplet_size))\n",
    "    num_n, num_e = max((2,size)),max((2,size))\n",
    "    possible_nodes = [int(random.uniform(1,nSize)) \n",
    "                      for i in range(num_n)]\n",
    "    possible_edges = [int(random.uniform(1,eSize)) \n",
    "                      for i in range(num_e)]\n",
    "    graph = []\n",
    "    for i in range(size):\n",
    "        graph.append((possible_nodes[int(random.uniform(0, num_n-1))],\n",
    "                      possible_edges[int(random.uniform(0, num_e-1))],\n",
    "                     possible_nodes[int(random.uniform(0, num_n-1))]))\n",
    "    quicksort(graph)\n",
    "    for i,(s,p,o) in enumerate(graph):\n",
    "        s = to_array(s, node_encoding_size)\n",
    "        o = to_array(o, node_encoding_size)\n",
    "        p = to_array(p, edge_encoding_size)\n",
    "        triplets[i, :] = np.concatenate((s, p, o))\n",
    "    return triplets\n",
    "\n",
    "\n",
    "\n",
    "def graph_train_generator_RNN(mi_size, ma_size, nSize, eSize):\n",
    "    while True:\n",
    "        size = int(random.uniform(mi_size, ma_size))\n",
    "        x_encoder = np.zeros((batch_size, size, triplet_size))\n",
    "        x_decoder = np.zeros((batch_size, size + 1, triplet_size))\n",
    "        y_decoder = np.zeros((batch_size, size + 1, triplet_size))\n",
    "        for i in range(batch_size):\n",
    "            x_encoder[i, :, :] = random_graph_triples(size, nSize, eSize)\n",
    "            # decoder starts with zeros and is one timestep late\n",
    "            x_decoder[i, 1:, :] = x_encoder[i, :, :]\n",
    "            y_decoder[i:, :-1, :] = x_encoder[i, :, :]\n",
    "        y = [\n",
    "            y_decoder[:,:,:node_encoding_size],\n",
    "            y_decoder[:,:,node_encoding_size:-node_encoding_size],\n",
    "            y_decoder[:,:,-node_encoding_size:]\n",
    "            ]    \n",
    "        if t != 1:\n",
    "            y = y_decoder\n",
    "        yield [x_encoder, x_decoder],y\n",
    "\n",
    "def graph_train_generator_Dense(mi_size, ma_size, nSize, eSize):\n",
    "    if ma_size > graph_size:\n",
    "        ma_size = graph_size\n",
    "    if mi_size > graph_size:\n",
    "        mi_size = graph_size-1\n",
    "    while True:\n",
    "        size = int(random.uniform(mi_size, ma_size))\n",
    "        x_encoder = np.zeros((batch_size, size, triplet_size))\n",
    "        y_decoder = np.zeros((batch_size, graph_size, triplet_size))\n",
    "        for i in range(batch_size):\n",
    "            x_encoder[i, :, :] = random_graph_triples(size, nSize, eSize)\n",
    "            # decoder starts with zeros and is one timestep late\n",
    "            y_decoder[i, :size, :] = x_encoder[i, :, :]\n",
    "        yield x_encoder, y_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "uw9g5XsbGjwx",
    "outputId": "ad0a9522-006b-4bf2-8c1d-5dced8c43ee3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph_train_generator_RNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3a8d568d9c67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_train_generator_RNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph_train_generator_RNN' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "gen = graph_train_generator_RNN(3,3,10,10)\n",
    "for x,y in gen:\n",
    "  print(x)\n",
    "  print(y[0].shape)\n",
    "  print(y[1].shape)\n",
    "  print(y[2].shape)\n",
    "  break\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mI9AXwqK4Zlo"
   },
   "source": [
    "\n",
    "#Encoder types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hdi1QsUH4Zls"
   },
   "outputs": [],
   "source": [
    "def create_encoder_lstm(inputs,return_state=True):\n",
    "    # Define an input sequence and process it.\n",
    "    #inputs = Dense(triplet_size*6,activation='relu')(inputs)\n",
    "    #inputs = Dense(triplet_size*12,activation='relu')(inputs)\n",
    "    encoder = LSTM(hidden_state_dim, return_state=return_state)\n",
    "    encoder_output, state_h, state_c = encoder(inputs)\n",
    "    \n",
    "    encoder_state = [state_h, state_c]\n",
    "    return encoder_output, encoder_state\n",
    "\n",
    "def create_encoder_gru(inputs,return_state=True):\n",
    "    # Define an input sequence and process it.\n",
    "    #inputs = Dense(triplet_size*6,activation='relu')(inputs)\n",
    "    #inputs = Dense(triplet_size*12,activation='relu')(inputs)\n",
    "    encoder = GRU(hidden_state_dim, return_state=return_state)\n",
    "    encoder_outputs, encoder_state = encoder(inputs)\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    return encoder_outputs, encoder_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKtBUqr94Zlz"
   },
   "source": [
    "#Decoder types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mrHgohcw4Zl4"
   },
   "outputs": [],
   "source": [
    "# only works with encoder_state generated from lstm encoder\n",
    "def create_decoder_lstm(encoder_state,inputs):\n",
    "    decoder_lstm = LSTM(hidden_state_dim, return_sequences=True,\n",
    "                        return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(inputs,\n",
    "                                         initial_state=encoder_state)\n",
    "    return decoder_outputs\n",
    "\n",
    "# only works with encoder_state generated from lstm encoder\n",
    "def create_decoder_gru(encoder_state,inputs):\n",
    "    decoder_gru = GRU(hidden_state_dim, return_sequences=True,\n",
    "                      return_state=True)\n",
    "    decoder_outputs, _ = decoder_gru(inputs,\n",
    "                                         initial_state=encoder_state)\n",
    "    return decoder_outputs\n",
    "\n",
    "def create_decoder_dense(encoder_state):\n",
    "    decoder_dense = Dense(hidden_state_dim*4,\n",
    "                          activation='relu')(encoder_state)\n",
    "    #decoder_dense = Dense(hidden_state_dim*2,\n",
    "    #                      activation='tanh')(decoder_dense)\n",
    "    decoder_dense = Dense(triplet_size*graph_size,\n",
    "                          activation='sigmoid')(decoder_dense)\n",
    "    decoder_dense = Reshape((graph_size,triplet_size))(decoder_dense)\n",
    "    return decoder_dense\n",
    "  \n",
    "\n",
    "def create_decoder_cnn(encoder_state):\n",
    "    decoder_dense = Reshape((w,h,1))(encoder_state)\n",
    "    decoder_dense = Conv2D(16,5,activation='relu')(decoder_dense)\n",
    "    decoder_dense = MaxPool2D((2,2))(decoder_dense)\n",
    "    decoder_dense = Conv2D(32,5,activation='relu')(decoder_dense)\n",
    "    decoder_dense = MaxPool2D((2,2))(decoder_dense)\n",
    "    decoder_dense = Flatten()(decoder_dense)\n",
    "    decoder_dense = Dense(triplet_size*graph_size,\n",
    "                          activation='sigmoid')(decoder_dense)\n",
    "    decoder_dense = Reshape((graph_size,triplet_size))(decoder_dense)\n",
    "    return decoder_dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TaeXuIry4ZmG"
   },
   "source": [
    "#Output unit after decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmYENjxU4ZmN"
   },
   "outputs": [],
   "source": [
    "def create_output_unit_cnn():\n",
    "    unit_inputs = Input(shape=(None,hidden_state_dim))\n",
    "    print(unit_inputs.shape)\n",
    "    reshaper = TimeDistributed(Reshape((32, 16,1)))\n",
    "    unit_outputs = reshaper(unit_inputs)\n",
    "    unit_outputs = TimeDistributed(Conv2D(16, 3,\n",
    "                                          activation='relu'))(unit_outputs)\n",
    "    unit_outputs = TimeDistributed(MaxPool2D(pool_size=(4, 4)))(unit_outputs)\n",
    "    unit_outputs = TimeDistributed(Flatten())(unit_outputs)\n",
    "    decoder_dense = TimeDistributed(Dense(triplet_size, activation='sigmoid'))\n",
    "    unit_outputs = decoder_dense(unit_outputs)\n",
    "    \n",
    "    return Model(unit_inputs,unit_outputs)\n",
    "\n",
    "def create_output_unit_dense():\n",
    "    unit_inputs = Input(shape=(None,hidden_state_dim))\n",
    "    decoder_dense = Dense(triplet_size, activation='sigmoid')\n",
    "    unit_outputs = decoder_dense(unit_inputs)\n",
    "    \n",
    "    return Model(unit_inputs,unit_outputs)\n",
    "  \n",
    "def create_output_unit_dense_onehot():\n",
    "    unit_inputs = Input(shape=(None,hidden_state_dim))\n",
    "    unit_outputs1 = Dense(node_encoding_size, activation='softmax',\n",
    "                          name='s')(unit_inputs)\n",
    "    unit_outputs2 = Dense(edge_encoding_size, activation='softmax',\n",
    "                          name='p')(unit_inputs)\n",
    "    unit_outputs3 = Dense(node_encoding_size, activation='softmax',\n",
    "                          name='o')(unit_inputs)\n",
    "    \n",
    "    return Model(unit_inputs,[unit_outputs1,unit_outputs2,unit_outputs3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0q5RU9274ZmU"
   },
   "source": [
    "#Creating Model RNN Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYGlhaM-4ZmW"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, triplet_size))\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, triplet_size))\n",
    "\n",
    "create_encoder = create_encoder_gru\n",
    "create_decoder = create_decoder_gru\n",
    "if t == 1:\n",
    "  create_unit = create_output_unit_dense_onehot\n",
    "else:\n",
    "  create_unit = create_output_unit_dense\n",
    "\n",
    "encoder_output,encoder_state = create_encoder(encoder_inputs)\n",
    "decoder_output = create_decoder_gru(encoder_state,decoder_inputs)\n",
    "unit = create_unit()\n",
    "decoder_output = unit(decoder_output)\n",
    "\n",
    "model = Model([encoder_inputs,decoder_inputs],decoder_output)\n",
    "loss='binary_crossentropy'\n",
    "loss_weight = [1]\n",
    "if t==1:\n",
    "  loss = ['categorical_crossentropy',\n",
    "          'categorical_crossentropy',\n",
    "          'categorical_crossentropy'\n",
    "         ]\n",
    "  loss_weight = [1,1,1]\n",
    "model.compile(optimizer='rmsprop', loss=loss,metrics=['accuracy'],loss_weights=loss_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "id": "PQbAK9Pgw1HM",
    "outputId": "a1e5dbe0-f118-4c7d-9643-875c053bfd89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None, 1152)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, None, 1152)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     [(None, 1024), (None 6687744     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     [(None, None, 1024), 6687744     input_5[0][0]                    \n",
      "                                                                 gru_3[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 [(None, None, 512),  1180800     gru_4[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 14,556,288\n",
      "Trainable params: 14,556,288\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "# model = keras.models.load_model('model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "V3oquEeI4Zmd",
    "outputId": "ae8c85fa-2e00-4a25-f275-c671f051b88f"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(graph_train_generator_RNN(1,graph_size,\n",
    "                    m_node,m_edge),\n",
    "                    steps_per_epoch=400,\n",
    "                    epochs=50,use_multiprocessing=True)\n",
    "# Save model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "XjotS0C3yLAc",
    "outputId": "acef6b34-00d0-4293-cbb3-78520673af07"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6LcOPrwexURU"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VjPoQB31ZHoF",
    "outputId": "119333bc-5af4-4f1c-a95d-5a09c995bbc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1qK74uj8idj2mpQo_dzm59FzCowwxQT3X\n"
     ]
    }
   ],
   "source": [
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': 'model_onehot_dense.h5'})\n",
    "uploaded.SetContentFile('model.h5')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pzHCLAcZZIeB"
   },
   "outputs": [],
   "source": [
    "id='1qK74uj8idj2mpQo_dzm59FzCowwxQT3X'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ug2Dbzoo4Zml"
   },
   "source": [
    "#Creating Model Dense Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnMLmnsyQ79_"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def myAccuracy(y_true, y_pred):\n",
    "    y_true = K.round(y_true)\n",
    "    y_pred = K.round(y_pred)\n",
    "    diff = K.abs(y_true-y_pred) #absolute difference between correct and predicted values\n",
    "    correct = K.less(diff,0.05) #tensor with 0 for false values and 1 for true values\n",
    "    return K.mean(correct) #sum all 1's and divide by the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "ftdroydJZs0z",
    "outputId": "79e682d4-f812-4a67-8c52-1b73a4b26959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "LUpoX2Am4Zmo",
    "outputId": "5860f2af-db5c-4345-98d2-c17cc5f35c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, None, 25)          0         \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 [(None, 1024), (None, 102 3225600   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 40, 25)            0         \n",
      "=================================================================\n",
      "Total params: 11,521,000\n",
      "Trainable params: 11,521,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, triplet_size))\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, triplet_size))\n",
    "\n",
    "create_encoder = create_encoder_gru\n",
    "create_decoder = create_decoder_dense\n",
    "create_unit = create_output_unit_cnn\n",
    "\n",
    "encoder_output,encoder_state = create_encoder(encoder_inputs)\n",
    "decoder_output = create_decoder(encoder_output)\n",
    "\n",
    "model = Model(encoder_inputs,decoder_output)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3690
    },
    "colab_type": "code",
    "id": "pyEUzizw4Zmw",
    "outputId": "721073ae-c098-4134-be39-144e30c02954"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(graph_train_generator_Dense(1,graph_size,\n",
    "                    m_node,m_edge),\n",
    "                    steps_per_epoch=400,\n",
    "                    epochs=100,use_multiprocessing=True)\n",
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u73UHZRR4Zm2"
   },
   "source": [
    "#Decode graph dense/cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "colab_type": "code",
    "id": "XSBmHscJ4Zm9",
    "outputId": "2ff5e0f9-d50b-4e55-9d6e-ce7bedee114c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79x1jPsl4ZnL"
   },
   "outputs": [],
   "source": [
    "s = 20\n",
    "print(triplet_size)\n",
    "graph = np.zeros((1,s,triplet_size))\n",
    "graph[0,:,:] = random_graph_triples(s,m_node,m_edge)\n",
    "graph_r = model.predict(graph)\n",
    "right = 0\n",
    "diff = 0\n",
    "for t1,t2 in zip(graph[0,:,:],graph_r[0,:,:]):\n",
    "  s,p,o = t1[:node_encoding_size],\\\n",
    "                    t1[node_encoding_size:node_encoding_size+edge_encoding_size],\\\n",
    "                    t1[-node_encoding_size:]\n",
    "  s1,p1,o1 = t2[:node_encoding_size],\\\n",
    "                    t2[node_encoding_size:node_encoding_size+edge_encoding_size],\\\n",
    "                    t2[-node_encoding_size:]\n",
    "  s,p,o,s1,p1,o1 = to_int(s),to_int(p),to_int(o),to_int(s1),to_int(p1),to_int(o1)\n",
    "  if s == s1 and p == p1 and o == o1:\n",
    "    right += 1\n",
    "  else:\n",
    "    diff += 1\n",
    "    #print('g1: ',s,p,o,' g2: ',s1,p1,o1)\n",
    "print('right: ',right, ' diff: ',diff)\n",
    "print(\"input graph:\")\n",
    "print_graphs(graph)\n",
    "print(\"output graph:\")\n",
    "print_graphs(graph_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djAnMvrt4ZnW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "graph_encoder.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "hack",
   "language": "python",
   "name": "hack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
